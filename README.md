#<img width="1536" height="1024" alt="ChatGPT Image Nov 19, 2025 at 01_54_50 PM" src="https://github.com/user-attachments/assets/e72fd5f6-09a3-409c-af95-338389627753" />
 Telco Churn Analysis - Machine Learning

This project performs an end-to-end customer churn analysis using the Telco Customer Churn dataset.  
The workflow includes exploratory data analysis (EDA), data preprocessing, feature engineering, model building, and model comparison based on performance metrics.

---

## ğŸ“Œ Project Workflow

### ğŸ” 1. Exploratory Data Analysis (EDA)
- Overview of numerical and categorical variables  
- Churn distribution analysis  
- Detection of correlations and important patterns  
- Visualization of key churn drivers  

### ğŸ§¹ 2. Data Preprocessing
- Identification and handling of missing values  
- Outlier detection and treatment (IQR-based methods)  
- Variable transformations (log, binning, etc.)  
- Encoding of categorical variables  
- Standardization and scaling for model readiness  

### ğŸ— 3. Feature Engineering
- Creating new features (e.g., tenure groups, total charges ratios, service counts)  
- Enhancing predictive power by combining related variables  
- Handling rare categories  
- Feature selection for better model performance  

### ğŸ¤– 4. Machine Learning Models
The following models were trained and compared:

- Logistic Regression  
- Random Forest Classifier  
- Gradient Boosting  
- XGBoost / LightGBM (if applicable)  
- KNN  
- Decision Tree  
- Support Vector Machine  

### ğŸ“Š 5. Model Evaluation
Models were evaluated using:

- Accuracy  
- Recall  
- Precision  
- F1 Score  
- ROCâ€“AUC  
- Confusion Matrix  

ğŸ“Œ **The best model was selected based on accuracy (and additional metrics where needed).**

### â­ Key Results  
- Feature engineering significantly improved model accuracy  
- Contract type, monthly charges, and tenure were among the most important predictors  
- Correctly handling outliers and missing values increased model stability  
- Tree-based models generally performed better than linear models  

## ğŸ“Š Model Performance Comparison

| Model           | Accuracy | AUC    | Recall | Precision | F1 Score |
|-----------------|----------|--------|--------|-----------|----------|
| Logistic Regression | 0.8059 | 0.8484 | 0.5388 | 0.6661 | 0.5956 |
| KNN             | 0.7686 | 0.7804 | 0.5265 | 0.5690 | 0.5469 |
| CART (Decision Tree) | 0.7291 | 0.6573 | 0.5029 | 0.4901 | 0.4961 |
| Random Forest   | 0.7890 | 0.8251 | 0.4853 | 0.6340 | 0.5497 |
| XGBoost         | 0.7822 | 0.8237 | 0.5046 | 0.6082 | 0.5514 |
| LightGBM        | 0.7961 | 0.8353 | 0.5211 | 0.6432 | 0.5757 |
| CatBoost        | 0.7975 | 0.8405 | 0.5131 | 0.6503 | 0.5736 |

â¡ï¸ **Best overall (balanced performance): Logistic Regression (Accuracy), LightGBM & CatBoost (AUC & Precision).**
## ğŸ”§ Hyperparameter Optimization Results

| Model | Before Accuracy | After Accuracy | Best Params |
|-------|-----------------|----------------|--------------|
| Logistic Regression | 0.8059 | 0.8075 | {'C': 0.1} |
| KNN | 0.7686 | 0.7774 | {'n_neighbors': 7} |
| CART | 0.7264 | 0.7815 | {'max_depth': 7} |
| Random Forest | 0.7872 | 0.7906 | {'n_estimators': 500} |
| XGBoost | 0.7822 | 0.8011 | {'learning_rate': 0.1, 'max_depth': 5} |


--------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ‡¹ğŸ‡· **Telco MÃ¼ÅŸteri Terk Analizi - Makine Ã–ÄŸrenmesi**

Bu projede Telco Customer Churn veri seti kullanÄ±larak uÃ§tan uca bir mÃ¼ÅŸteri terk analizi yapÄ±lmÄ±ÅŸtÄ±r.  
Analiz sÃ¼reci; keÅŸifsel veri analizi, veri Ã¶n iÅŸleme, feature engineering, makine Ã¶ÄŸrenmesi modelleme ve model karÅŸÄ±laÅŸtÄ±rmalarÄ±nÄ± iÃ§ermektedir.

---

## ğŸ“Œ Proje Ä°ÅŸ AkÄ±ÅŸÄ±

### ğŸ” 1. KeÅŸifsel Veri Analizi (EDA)
- SayÄ±sal ve kategorik deÄŸiÅŸkenlere genel bakÄ±ÅŸ  
- Churn oranÄ±nÄ±n incelenmesi  
- KorelasyonlarÄ±n analiz edilmesi  
- Ã–nemli churn etkileyicilerinin gÃ¶rselleÅŸtirilmesi  

### ğŸ§¹ 2. Veri Ã–n Ä°ÅŸleme
- Eksik deÄŸerlerin tespiti ve doldurulmasÄ±  
- AykÄ±rÄ± deÄŸerlerin belirlenmesi ve mÃ¼dahalesi (IQR yÃ¶ntemleri)  
- DeÄŸiÅŸken dÃ¶nÃ¼ÅŸÃ¼mleri (logaritmik, gruplama vb.)  
- Kategorik deÄŸiÅŸkenlerin encode edilmesi  
- StandartlaÅŸtÄ±rma ve Ã¶lÃ§eklendirme  

### ğŸ— 3. Feature Engineering
- Yeni deÄŸiÅŸkenlerin oluÅŸturulmasÄ± (Ã¶r. tenure gruplarÄ±, servis sayÄ±larÄ±)  
- DeÄŸiÅŸken birleÅŸtirme / ayrÄ±ÅŸtÄ±rma  
- Nadir kategorilerin dÃ¼zenlenmesi  
- PerformansÄ± artÄ±ran deÄŸiÅŸken seÃ§imi  

### ğŸ¤– 4. Makine Ã–ÄŸrenmesi Modelleri
AÅŸaÄŸÄ±daki modeller eÄŸitilip karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±:

- Lojistik Regresyon  
- Random Forest  
- Gradient Boosting  
- XGBoost / LightGBM  
- KNN  
- Decision Tree  
- SVM  

### ğŸ“Š 5. Model DeÄŸerlendirme
Modeller aÅŸaÄŸÄ±daki metriklere gÃ¶re deÄŸerlendirildi:

- Accuracy  
- Recall  
- Precision  
- F1 Skoru  
- ROCâ€“AUC  
- Confusion Matrix  

ğŸ“Œ **En iyi model accuracy ve diÄŸer metriklere gÃ¶re seÃ§ildi.**

---

## â­ Ã–nemli Bulgular
- Feature engineering model performansÄ±nÄ± belirgin ÅŸekilde artÄ±rdÄ±  
- SÃ¶zleÅŸme tÃ¼rÃ¼, aylÄ±k Ã¼cret ve kullanÄ±m sÃ¼resi churn Ã¼zerinde kritik Ã¶neme sahiptir  
- Outlier ve eksik deÄŸer iÅŸlemleri model kararlÄ±lÄ±ÄŸÄ±nÄ± gÃ¼Ã§lendirdi  
- AÄŸaÃ§ tabanlÄ± modeller lineer modellere gÃ¶re daha iyi sonuÃ§ verdi  

---

## ğŸ“‚ Repository Content
- `notebooks/` â†’ EDA ve modelleme adÄ±mlarÄ±nÄ±n notebook dosyalarÄ±  
- `data/` â†’ Dataset (paylaÅŸÄ±m koÅŸullarÄ±na uygun ÅŸekilde)  
- `src/` â†’ Kod dosyalarÄ±  
- `README.md` â†’ Proje aÃ§Ä±klamasÄ±  

---

## â­ If you found this project helpful, please consider giving it a star!
